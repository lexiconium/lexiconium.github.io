<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>What Did I Say?</title>
    <link>https://lexiconium.github.io/</link>
    <description>Recent content on What Did I Say?</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 06 Jul 2022 18:01:45 +0900</lastBuildDate><atom:link href="https://lexiconium.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenAI의 Video PreTraining (VPT) 리뷰</title>
      <link>https://lexiconium.github.io/posts/openai_vpt/</link>
      <pubDate>Wed, 06 Jul 2022 18:01:45 +0900</pubDate>
      
      <guid>https://lexiconium.github.io/posts/openai_vpt/</guid>
      <description>최근 수 년간 많은 pretrained 모델들이 다양한 downstream task들에서 활약하며 방대한 규모의, 논문에서 말하길 noisy internet-scale, dataset을 통한 pretraining 패러다임이 natural language processing 및 computer vision 분야에서 유효하다는 것이 증명됐다. 다만 이와 같은 방법론이 아직 널리 퍼지지 않은 분야가 있는데, 바로 로보틱스, 게이밍 및 컴퓨터 사용 등의 sequential decision 분야이다. 이에 대한 유인은 sequential decision과 관련된 data 그 자체는 풍부하나 그러한 data의 대부분이 직전 프레임에서 어떤 행동을 취해야 다음 프레임으로 넘어가는지에 대한 정보를 포함하고 있지 않음에 있다.</description>
    </item>
    
    
    
  </channel>
</rss>
